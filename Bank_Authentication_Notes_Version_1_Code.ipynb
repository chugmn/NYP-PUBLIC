{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8xhbJkejRXplGF6cBnjo5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chugmn/NYP-PUBLIC/blob/main/Bank_Authentication_Notes_Version_1_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7nLDXgsgAIj",
        "outputId": "b2dca24c-ec04-4813-f4fe-640d08c305bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   variance  skewness  kurtosis  entropy  class\n",
            "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
            "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
            "2   3.86600   -2.6383    1.9242  0.10645      0\n",
            "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
            "4   0.32924   -4.4552    4.5718 -0.98880      0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
        "columns = [\"variance\", \"skewness\", \"kurtosis\", \"entropy\", \"class\"]\n",
        "data = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Display the first few rows\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = data.drop(\"class\", axis=1).values\n",
        "y = data[\"class\"].values\n",
        "\n",
        "# Manually split data into 80% train and 20% test\n",
        "split_index = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Normalize the features\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
        "X_test = (X_test - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)  # Use training mean/std\n",
        "\n"
      ],
      "metadata": {
        "id": "D_X6rrG4UZMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Build the model\n",
        "#model = keras.Sequential([\n",
        "#    layers.Input(shape=(X_train.shape[1],)),  # Use Input layer for input shape\n",
        "#    layers.Dense(16, activation='relu'),\n",
        "#    layers.Dense(8, activation='relu'),\n",
        "#    layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "#])\n",
        "\n",
        "# Compile the model\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 2nd try :\n",
        "#def build_model():\n",
        " #   model = tf.keras.Sequential([\n",
        "#      tf.keras.layers.Input(shape=(X.shape[1],)),  # Specify input shape here\n",
        "#        tf.keras.layers.Dense(16, activation='relu'),\n",
        "#        tf.keras.layers.Dense(8, activation='relu'),\n",
        "#        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "#    ])\n",
        "#    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#    return model\n",
        "\n",
        "# 3rd try :\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "def build_model():\n",
        "    inputs = Input(shape=(X.shape[1],))  # Explicitly define input\n",
        "    x = Dense(16, activation='relu')(inputs)\n",
        "    x = Dense(8, activation='relu')(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)  # Wrap in a functional model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6icZISC5csPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN4CODQcg14f",
        "outputId": "bb779731-12c6-45e8-92cc-c99238664273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 1.1414 - val_accuracy: 0.9455 - val_loss: 0.2937\n",
            "Epoch 2/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0550 - val_accuracy: 0.9636 - val_loss: 0.1878\n",
            "Epoch 3/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0104 - val_accuracy: 0.9591 - val_loss: 0.1694\n",
            "Epoch 4/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0196 - val_accuracy: 0.9500 - val_loss: 0.2104\n",
            "Epoch 5/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9591 - val_loss: 0.1828\n",
            "Epoch 6/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9591 - val_loss: 0.1825\n",
            "Epoch 7/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9591 - val_loss: 0.1809\n",
            "Epoch 8/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9591 - val_loss: 0.1858\n",
            "Epoch 9/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9591 - val_loss: 0.1876\n",
            "Epoch 10/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9591 - val_loss: 0.1883\n",
            "Epoch 11/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5383e-04 - val_accuracy: 0.9591 - val_loss: 0.1875\n",
            "Epoch 12/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5680e-04 - val_accuracy: 0.9591 - val_loss: 0.1897\n",
            "Epoch 13/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7146e-04 - val_accuracy: 0.9591 - val_loss: 0.1928\n",
            "Epoch 14/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9333e-04 - val_accuracy: 0.9636 - val_loss: 0.1866\n",
            "Epoch 15/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8240e-04 - val_accuracy: 0.9591 - val_loss: 0.1973\n",
            "Epoch 16/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1045e-04 - val_accuracy: 0.9591 - val_loss: 0.2002\n",
            "Epoch 17/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9748e-04 - val_accuracy: 0.9636 - val_loss: 0.1959\n",
            "Epoch 18/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4446e-04 - val_accuracy: 0.9591 - val_loss: 0.1998\n",
            "Epoch 19/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8039e-04 - val_accuracy: 0.9636 - val_loss: 0.1954\n",
            "Epoch 20/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2625e-04 - val_accuracy: 0.9591 - val_loss: 0.2085\n",
            "Epoch 21/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9124e-04 - val_accuracy: 0.9636 - val_loss: 0.2024\n",
            "Epoch 22/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5119e-04 - val_accuracy: 0.9591 - val_loss: 0.2087\n",
            "Epoch 23/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6902e-04 - val_accuracy: 0.9591 - val_loss: 0.2043\n",
            "Epoch 24/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3809e-04 - val_accuracy: 0.9591 - val_loss: 0.2109\n",
            "Epoch 25/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6546e-04 - val_accuracy: 0.9591 - val_loss: 0.2079\n",
            "Epoch 26/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6493e-04 - val_accuracy: 0.9636 - val_loss: 0.2069\n",
            "Epoch 27/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6406e-04 - val_accuracy: 0.9636 - val_loss: 0.2085\n",
            "Epoch 28/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3269e-04 - val_accuracy: 0.9636 - val_loss: 0.2145\n",
            "Epoch 29/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8109e-04 - val_accuracy: 0.9636 - val_loss: 0.2134\n",
            "Epoch 30/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1575e-04 - val_accuracy: 0.9591 - val_loss: 0.2180\n",
            "Epoch 31/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8257e-04 - val_accuracy: 0.9636 - val_loss: 0.2103\n",
            "Epoch 32/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1011e-04 - val_accuracy: 0.9636 - val_loss: 0.2164\n",
            "Epoch 33/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.2328e-04 - val_accuracy: 0.9636 - val_loss: 0.2147\n",
            "Epoch 34/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7947e-04 - val_accuracy: 0.9636 - val_loss: 0.2171\n",
            "Epoch 35/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0611e-04 - val_accuracy: 0.9591 - val_loss: 0.2222\n",
            "Epoch 36/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8299e-04 - val_accuracy: 0.9591 - val_loss: 0.2249\n",
            "Epoch 37/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8899e-04 - val_accuracy: 0.9591 - val_loss: 0.2262\n",
            "Epoch 38/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6487e-04 - val_accuracy: 0.9636 - val_loss: 0.2257\n",
            "Epoch 39/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3432e-04 - val_accuracy: 0.9636 - val_loss: 0.2229\n",
            "Epoch 40/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7646e-04 - val_accuracy: 0.9591 - val_loss: 0.2299\n",
            "Epoch 41/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0513e-04 - val_accuracy: 0.9636 - val_loss: 0.2268\n",
            "Epoch 42/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0113e-05 - val_accuracy: 0.9636 - val_loss: 0.2268\n",
            "Epoch 43/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1705e-04 - val_accuracy: 0.9636 - val_loss: 0.2289\n",
            "Epoch 44/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2224e-04 - val_accuracy: 0.9636 - val_loss: 0.2278\n",
            "Epoch 45/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.1382e-05 - val_accuracy: 0.9636 - val_loss: 0.2287\n",
            "Epoch 46/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1209e-04 - val_accuracy: 0.9636 - val_loss: 0.2328\n",
            "Epoch 47/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1312e-04 - val_accuracy: 0.9636 - val_loss: 0.2294\n",
            "Epoch 48/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5402e-05 - val_accuracy: 0.9636 - val_loss: 0.2337\n",
            "Epoch 49/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5620e-05 - val_accuracy: 0.9636 - val_loss: 0.2318\n",
            "Epoch 50/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0293e-04 - val_accuracy: 0.9636 - val_loss: 0.2346\n",
            "Epoch 51/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4387e-05 - val_accuracy: 0.9636 - val_loss: 0.2342\n",
            "Epoch 52/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1503e-05 - val_accuracy: 0.9636 - val_loss: 0.2374\n",
            "Epoch 53/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4750e-05 - val_accuracy: 0.9636 - val_loss: 0.2381\n",
            "Epoch 54/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2528e-05 - val_accuracy: 0.9636 - val_loss: 0.2362\n",
            "Epoch 55/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.5508e-05 - val_accuracy: 0.9636 - val_loss: 0.2405\n",
            "Epoch 56/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1216e-04 - val_accuracy: 0.9636 - val_loss: 0.2465\n",
            "Epoch 57/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2083e-05 - val_accuracy: 0.9636 - val_loss: 0.2460\n",
            "Epoch 58/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3908e-05 - val_accuracy: 0.9636 - val_loss: 0.2422\n",
            "Epoch 59/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6784e-05 - val_accuracy: 0.9636 - val_loss: 0.2395\n",
            "Epoch 60/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1502e-05 - val_accuracy: 0.9636 - val_loss: 0.2463\n",
            "Epoch 61/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7485e-05 - val_accuracy: 0.9636 - val_loss: 0.2462\n",
            "Epoch 62/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4854e-05 - val_accuracy: 0.9636 - val_loss: 0.2434\n",
            "Epoch 63/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6303e-05 - val_accuracy: 0.9636 - val_loss: 0.2475\n",
            "Epoch 64/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9282e-05 - val_accuracy: 0.9636 - val_loss: 0.2426\n",
            "Epoch 65/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9070e-05 - val_accuracy: 0.9636 - val_loss: 0.2456\n",
            "Epoch 66/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5477e-05 - val_accuracy: 0.9636 - val_loss: 0.2477\n",
            "Epoch 67/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5173e-05 - val_accuracy: 0.9636 - val_loss: 0.2467\n",
            "Epoch 68/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5044e-05 - val_accuracy: 0.9636 - val_loss: 0.2480\n",
            "Epoch 69/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2382e-05 - val_accuracy: 0.9636 - val_loss: 0.2571\n",
            "Epoch 70/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2741e-05 - val_accuracy: 0.9636 - val_loss: 0.2462\n",
            "Epoch 71/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9553e-05 - val_accuracy: 0.9636 - val_loss: 0.2512\n",
            "Epoch 72/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2930e-05 - val_accuracy: 0.9636 - val_loss: 0.2533\n",
            "Epoch 73/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0228e-05 - val_accuracy: 0.9636 - val_loss: 0.2552\n",
            "Epoch 74/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4147e-05 - val_accuracy: 0.9636 - val_loss: 0.2514\n",
            "Epoch 75/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7994e-05 - val_accuracy: 0.9636 - val_loss: 0.2512\n",
            "Epoch 76/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3465e-05 - val_accuracy: 0.9636 - val_loss: 0.2534\n",
            "Epoch 77/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5190e-05 - val_accuracy: 0.9636 - val_loss: 0.2537\n",
            "Epoch 78/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5937e-05 - val_accuracy: 0.9636 - val_loss: 0.2574\n",
            "Epoch 79/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0171e-05 - val_accuracy: 0.9636 - val_loss: 0.2570\n",
            "Epoch 80/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7576e-05 - val_accuracy: 0.9636 - val_loss: 0.2619\n",
            "Epoch 81/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8240e-05 - val_accuracy: 0.9636 - val_loss: 0.2645\n",
            "Epoch 82/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1395e-05 - val_accuracy: 0.9636 - val_loss: 0.2649\n",
            "Epoch 83/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9191e-05 - val_accuracy: 0.9636 - val_loss: 0.2573\n",
            "Epoch 84/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2685e-05 - val_accuracy: 0.9636 - val_loss: 0.2585\n",
            "Epoch 85/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1719e-05 - val_accuracy: 0.9636 - val_loss: 0.2632\n",
            "Epoch 86/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5006e-05 - val_accuracy: 0.9636 - val_loss: 0.2634\n",
            "Epoch 87/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7468e-05 - val_accuracy: 0.9636 - val_loss: 0.2640\n",
            "Epoch 88/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6826e-05 - val_accuracy: 0.9636 - val_loss: 0.2621\n",
            "Epoch 89/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5232e-05 - val_accuracy: 0.9636 - val_loss: 0.2620\n",
            "Epoch 90/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6299e-05 - val_accuracy: 0.9636 - val_loss: 0.2657\n",
            "Epoch 91/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1597e-05 - val_accuracy: 0.9636 - val_loss: 0.2619\n",
            "Epoch 92/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6370e-05 - val_accuracy: 0.9636 - val_loss: 0.2653\n",
            "Epoch 93/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0552e-05 - val_accuracy: 0.9636 - val_loss: 0.2651\n",
            "Epoch 94/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5911e-05 - val_accuracy: 0.9636 - val_loss: 0.2723\n",
            "Epoch 95/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1811e-05 - val_accuracy: 0.9636 - val_loss: 0.2677\n",
            "Epoch 96/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0559e-05 - val_accuracy: 0.9636 - val_loss: 0.2712\n",
            "Epoch 97/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6522e-05 - val_accuracy: 0.9636 - val_loss: 0.2671\n",
            "Epoch 98/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9593e-05 - val_accuracy: 0.9636 - val_loss: 0.2729\n",
            "Epoch 99/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1845e-05 - val_accuracy: 0.9636 - val_loss: 0.2714\n",
            "Epoch 100/100\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9456e-05 - val_accuracy: 0.9636 - val_loss: 0.2756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "# Assuming X and y are your input and target data respectively\n",
        "# Set number of splits (folds) for cross-validation\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# To store the accuracy of each fold\n",
        "cv_scores = []\n",
        "\n",
        "# Define the model architecture in a function for reusability\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Dense(12, input_dim=X.shape[1], activation='relu'),\n",
        "        Dense(8, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.01),\n",
        "                  loss=BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Cross-validation loop\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Create a new model instance for each fold\n",
        "    model = create_model()\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    scores = model.evaluate(X_val, y_val, verbose=0)\n",
        "    cv_scores.append(scores[1])  # scores[1] is accuracy\n",
        "\n",
        "# Print cross-validation results\n",
        "print(f\"Cross-Validation Accuracies: {cv_scores}\")\n",
        "print(f\"Mean Accuracy: {np.mean(cv_scores)}\")\n",
        "print(f\"Standard Deviation: {np.std(cv_scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4yxt4YejCP8",
        "outputId": "c87c0c9b-a662-472b-9a05-69b50295e810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracies: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "Mean Accuracy: 1.0\n",
            "Standard Deviation: 0.0\n"
          ]
        }
      ]
    }
  ]
}